# Kahani Environment Configuration# Environment variables for Kahani

# Copy this file to .env and update with your settings# Copy this file to .env and customize the values



# ==========================================# Database Configuration

# Database ConfigurationDATABASE_URL=sqlite:///./data/kahani.db

# ==========================================# For PostgreSQL: DATABASE_URL=postgresql://username:password@localhost:5432/kahani

# SQLite (default - easiest for getting started)

DATABASE_URL=sqlite:///./data/kahani.db# Security

JWT_SECRET_KEY=your-super-secret-jwt-key-change-this-in-production

# PostgreSQL (recommended for production)JWT_ALGORITHM=HS256

# DATABASE_URL=postgresql://kahani:kahani_password@postgres:5432/kahaniACCESS_TOKEN_EXPIRE_MINUTES=30

# POSTGRES_DB=kahani

# POSTGRES_USER=kahani# Admin User (created on first run)

# POSTGRES_PASSWORD=change_this_passwordADMIN_EMAIL=admin@localhost

ADMIN_PASSWORD=changeme123

# ==========================================

# Security & Authentication# LLM Configuration

# ==========================================LLM_BASE_URL=http://localhost:1234/v1

SECRET_KEY=kahani-secret-key-change-in-productionLLM_API_KEY=not-needed-for-local

JWT_SECRET_KEY=your-super-secret-jwt-key-change-in-productionLLM_MODEL=local-model

LLM_MAX_TOKENS=2048

# ==========================================LLM_TEMPERATURE=0.7

# LLM Configuration

# ==========================================# Application Settings

# For LM Studio (default)APP_NAME=Kahani

LLM_BASE_URL=http://host.docker.internal:1234/v1APP_VERSION=0.1.0

LLM_API_KEY=not-needed-for-localDEBUG=true

LLM_MODEL=local-modelCORS_ORIGINS=["http://localhost:3000"]



# For OpenAI# File Storage

# LLM_BASE_URL=https://api.openai.com/v1DATA_DIR=./data

# LLM_API_KEY=sk-your-openai-api-keyEXPORT_DIR=./exports

# LLM_MODEL=gpt-4MAX_STORY_SIZE_MB=10

MAX_USERS=100

# For Ollama (local)

# LLM_BASE_URL=http://ollama:11434/v1# Features

# LLM_API_KEY=not-neededENABLE_REGISTRATION=true

# LLM_MODEL=llama2ENABLE_STORY_SHARING=true

ENABLE_PUBLIC_STORIES=false

# ==========================================

# TTS Configuration (Optional)# Logging

# Configure these OR use the Settings UI after first runLOG_LEVEL=INFO

# ==========================================LOG_FILE=./logs/kahani.log
# TTS Provider type: openai-compatible, kokoro, chatterbox
TTS_PROVIDER=openai-compatible

# TTS API URL (examples below)
# For Kokoro TTS:
# TTS_API_URL=http://host.docker.internal:8080/v1/audio/speech
# For Chatterbox TTS:
# TTS_API_URL=http://host.docker.internal:5000/v1/audio/speech
# For OpenAI:
# TTS_API_URL=https://api.openai.com/v1/audio/speech

TTS_API_URL=http://host.docker.internal:8080/v1/audio/speech
TTS_API_KEY=

# ==========================================
# Frontend Configuration
# ==========================================
NEXT_PUBLIC_API_BASE_URL=http://localhost:8000
NODE_ENV=development

# ==========================================
# Application Settings
# ==========================================
DEBUG=false
CORS_ORIGINS=["http://localhost:3000", "http://127.0.0.1:3000"]

# ==========================================
# Optional: Redis (for caching)
# ==========================================
# REDIS_URL=redis://redis:6379/0

# ==========================================
# Docker Compose Profiles
# ==========================================
# Uncomment to enable optional services:
# COMPOSE_PROFILES=llm,redis,proxy

# ==========================================
# Production Settings
# ==========================================
# For production deployment, set these:
# NODE_ENV=production
# DEBUG=false
# Use strong passwords and keys
# Use PostgreSQL instead of SQLite
# Enable HTTPS with proper certificates
