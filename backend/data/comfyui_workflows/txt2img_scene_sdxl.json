{
  "workflow_name": "txt2img_scene_sdxl",
  "model_type": "sdxl",
  "description": "SDXL scene generation without character references",
  "placeholders": {
    "POSITIVE_PROMPT": {"node_id": "6", "field": "text"},
    "NEGATIVE_PROMPT": {"node_id": "7", "field": "text"},
    "SEED": {"node_id": "3", "field": "seed"},
    "CHECKPOINT": {"node_id": "4", "field": "ckpt_name"},
    "WIDTH": {"node_id": "5", "field": "width"},
    "HEIGHT": {"node_id": "5", "field": "height"},
    "STEPS": {"node_id": "3", "field": "steps"},
    "CFG": {"node_id": "3", "field": "cfg"}
  },
  "workflow": {
    "3": {
      "class_type": "KSampler",
      "inputs": {
        "cfg": 1.5,
        "denoise": 1,
        "latent_image": ["5", 0],
        "model": ["4", 0],
        "negative": ["7", 0],
        "positive": ["6", 0],
        "sampler_name": "euler",
        "scheduler": "normal",
        "seed": 0,
        "steps": 4
      }
    },
    "4": {
      "class_type": "CheckpointLoaderSimple",
      "inputs": {
        "ckpt_name": "sdxl_lightning_4step.safetensors"
      }
    },
    "5": {
      "class_type": "EmptyLatentImage",
      "inputs": {
        "batch_size": 1,
        "height": 1024,
        "width": 1024
      }
    },
    "6": {
      "class_type": "CLIPTextEncode",
      "inputs": {
        "clip": ["4", 1],
        "text": "scene, environment, high quality, detailed"
      }
    },
    "7": {
      "class_type": "CLIPTextEncode",
      "inputs": {
        "clip": ["4", 1],
        "text": "low quality, blurry, deformed"
      }
    },
    "8": {
      "class_type": "VAEDecode",
      "inputs": {
        "samples": ["3", 0],
        "vae": ["4", 2]
      }
    },
    "9": {
      "class_type": "SaveImage",
      "inputs": {
        "filename_prefix": "kahani_scene",
        "images": ["8", 0]
      }
    }
  }
}
